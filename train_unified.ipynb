{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_notes = 128\n",
    "num_time_shifts = 100\n",
    "num_velocities = 32\n",
    "message_dim = 2*num_notes + num_velocities + num_time_shifts\n",
    "instrument_numbers = [0, 6, 40, 41, 42, 43, 45, 60, 68, 70, 71, 73]\n",
    "num_instruments = len(instrument_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EnsembleTransformer definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from https://pytorch.org/tutorials/beginner/transformer_tutorial.html.\n",
    "# Only change is the view/expand in forward (accounts for batches)\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=10000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.shape[0], :].unsqueeze(1).expand(-1, x.shape[1], -1)\n",
    "        return self.dropout(x)\n",
    "        \n",
    "\n",
    "# EnsembleTransformer: takes a history of MIDI messages \n",
    "# for instruments in an ensemble and generates a distribution for the next message,\n",
    "# as well as the instrument who should issue the message\n",
    "class EnsembleTransformer(torch.nn.Module):\n",
    "    # CONSTRUCTOR\n",
    "    # ARGUMENTS\n",
    "    # message_dim: dimension of a MIDI message\n",
    "    # embed_dim: dimension of message embedding\n",
    "    # num_instruments: number of instrument labels\n",
    "    # heads: number of attention heads\n",
    "    # attention_layers: number of attention layers\n",
    "    # ff_size: size of the feedforward output at the end of the decoder\n",
    "    def __init__(self, message_dim, embed_dim, num_instruments, heads, attention_layers, ff_size):\n",
    "        super(EnsembleTransformer, self).__init__()\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        # Indicates which channel is associated with each instrument, as well as\n",
    "        # the position of messages in time\n",
    "        self.position_encoding = PositionalEncoding(embed_dim)\n",
    "        \n",
    "        # The encoder computes attention over the instrument embeddings\n",
    "        self.i_embedding = torch.nn.Embedding(num_instruments, embed_dim)\n",
    "        encoder_layer = torch.nn.TransformerEncoderLayer(embed_dim, heads, ff_size)\n",
    "        self.encoder = torch.nn.TransformerEncoder(encoder_layer, attention_layers)\n",
    "        \n",
    "        # The decoder computes attention over the message history, using the above\n",
    "        # encoding as memory\n",
    "        self.embedding = torch.nn.Embedding(message_dim, embed_dim)\n",
    "        decoder_layer = torch.nn.TransformerDecoderLayer(embed_dim, heads, ff_size)\n",
    "        self.decoder = torch.nn.TransformerDecoder(decoder_layer, attention_layers)\n",
    "\n",
    "        # The decoding is passed through a linear layer to get the logits for the next message        \n",
    "        self.message_logits = torch.nn.Linear(embed_dim, message_dim)\n",
    "        \n",
    "        # The decoding becomes a query for attention across the instruments, which is used to\n",
    "        # predict the next instrument\n",
    "        self.inst_attention = torch.nn.MultiheadAttention(embed_dim, heads)\n",
    "    \n",
    "    # forward: generates a probability distribution for the next MIDI message\n",
    "    # and the channel that issues the message, given a message history for the instrument ensemble\n",
    "    # ARGUMENTS\n",
    "    # history: an LxBx2 tensor, where L is the length of the longest message history in\n",
    "    # the batch, and B is the batch size. The first index along dimension 2 stores the\n",
    "    # message number. The second stores the channel number. This should be END-PADDED\n",
    "    # along dimension 0. All time shifts should be associated with channel -1.\n",
    "    # mask: an LxB tensor, containing True in any locations where history contains\n",
    "    # padding\n",
    "    # instruments: a CxB tensor indicating the instrument number for each channel, where\n",
    "    # C is the maximum number of channels in the batch. This should be END-PADDED along dimension 0\n",
    "    # inst_mask: contains False where an instrument exists, True where it doesn't\n",
    "    # RETURN: two tensors. The first is LxBxD, representing the distribution for the next message at each time\n",
    "    # step (need to take the softmax to get actual probabilities). The second is LxBxC, representing the\n",
    "    # distribution for the next channel at each time step (need to take the softmax to get actual probabilities)\n",
    "    def forward(self, history, mask, instruments, inst_mask):\n",
    "        L = history.shape[0] # longest length\n",
    "        B = history.shape[1] # batch size\n",
    "        C = instruments.shape[0]\n",
    "        assert(mask.shape == (L, B))\n",
    "        assert(inst_mask.shape == (C, B))\n",
    "        \n",
    "        # CxBxD\n",
    "        inst_embed = self.position_encoding(torch.tanh(self.i_embedding(instruments)))\n",
    "        \n",
    "        inst_encoding = self.encoder(inst_embed, src_key_padding_mask=inst_mask.transpose(0, 1))\n",
    "        \n",
    "        # Which messages are time shifts?\n",
    "        time_shift_mask = history[:, :, 1] < 0\n",
    "        \n",
    "        # LxBxD, instrument embedding associated with each message\n",
    "        inst_sel = history[:, :, 1].unsqueeze(2).expand(-1, -1, self.embed_dim).clone()\n",
    "        inst_sel[time_shift_mask] = 0\n",
    "        \n",
    "        inst_tags = torch.gather(inst_embed, 0, inst_sel)\n",
    "        inst_tags[time_shift_mask] = 0\n",
    "        \n",
    "        # LxBxD\n",
    "        decoder_inputs = self.position_encoding(self.embedding(history[:, :, 0])) + inst_tags\n",
    "        \n",
    "        tgt_mask = torch.triu(torch.ones((L, L), dtype=torch.bool))\n",
    "        tgt_mask.fill_diagonal_(False)\n",
    "        tgt_key_padding_mask = mask.transpose(0, 1)\n",
    "        \n",
    "        decoding = self.decoder(decoder_inputs, inst_embed, \\\n",
    "                                tgt_mask=tgt_mask, \\\n",
    "                                tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                                memory_key_padding_mask=inst_mask.transpose(0, 1))\n",
    "        \n",
    "        # LxBxD\n",
    "        message_dist = self.message_logits(decoding)\n",
    "        \n",
    "        # channel_dist (BxLxC) contains the attention weights for each instrument.\n",
    "        # We have L queries (the elements of decoding). Our keys and values\n",
    "        # are the instrument embeddings\n",
    "        att_out, channel_dist = self.inst_attention(self.position_encoding(decoding), \\\n",
    "                                                    inst_embed, inst_embed,\n",
    "                                                    key_padding_mask = inst_mask.transpose(0, 1))\n",
    "        \n",
    "        return message_dist, channel_dist.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests for EnsembleTransformer\n",
    "We train with model.eval() to disable dropout, since these tests try to get the model to overfit to a small sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the model to overfit to a single song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 512\n",
    "heads = 4\n",
    "attention_layers = 6\n",
    "ff_size = 512\n",
    "\n",
    "grad_clip = 10\n",
    "\n",
    "model = EnsembleTransformer(message_dim, embed_dim, num_instruments, heads, attention_layers, ff_size)\n",
    "for p in model.parameters():\n",
    "    p.register_hook(lambda grad: torch.clamp(grad, -grad_clip, grad_clip))\n",
    "    \n",
    "model.eval() # Training with eval just to see if we can overfit without dropout\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('unified_transformer.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n",
      "Loss: 8.221643\n",
      "Starting epoch 1\n",
      "Loss: 5.686598\n",
      "Starting epoch 2\n",
      "Loss: 5.535431\n",
      "Starting epoch 3\n",
      "Loss: 4.788942\n",
      "Starting epoch 4\n",
      "Loss: 4.689373\n",
      "Starting epoch 5\n",
      "Loss: 4.483162\n",
      "Starting epoch 6\n",
      "Loss: 4.393062\n",
      "Starting epoch 7\n",
      "Loss: 4.381985\n",
      "Starting epoch 8\n",
      "Loss: 4.366362\n",
      "Starting epoch 9\n",
      "Loss: 4.304093\n",
      "Starting epoch 10\n",
      "Loss: 4.264818\n",
      "Starting epoch 11\n",
      "Loss: 4.295906\n",
      "Starting epoch 12\n",
      "Loss: 4.261703\n",
      "Starting epoch 13\n",
      "Loss: 4.245165\n",
      "Starting epoch 14\n",
      "Loss: 4.242423\n",
      "Starting epoch 15\n",
      "Loss: 4.222764\n",
      "Starting epoch 16\n",
      "Loss: 4.200438\n",
      "Starting epoch 17\n",
      "Loss: 4.200336\n",
      "Starting epoch 18\n",
      "Loss: 4.205481\n",
      "Starting epoch 19\n",
      "Loss: 4.184215\n",
      "Starting epoch 20\n",
      "Loss: 4.164371\n",
      "Starting epoch 21\n",
      "Loss: 4.159318\n",
      "Starting epoch 22\n",
      "Loss: 4.155161\n",
      "Starting epoch 23\n",
      "Loss: 4.150270\n",
      "Starting epoch 24\n",
      "Loss: 4.143007\n",
      "Starting epoch 25\n",
      "Loss: 4.126575\n",
      "Starting epoch 26\n",
      "Loss: 4.115974\n",
      "Starting epoch 27\n",
      "Loss: 4.112792\n",
      "Starting epoch 28\n",
      "Loss: 4.102180\n",
      "Starting epoch 29\n",
      "Loss: 4.093432\n",
      "Starting epoch 30\n",
      "Loss: 4.085574\n",
      "Starting epoch 31\n",
      "Loss: 4.076963\n",
      "Starting epoch 32\n",
      "Loss: 4.067157\n",
      "Starting epoch 33\n",
      "Loss: 4.058324\n",
      "Starting epoch 34\n",
      "Loss: 4.051449\n",
      "Starting epoch 35\n",
      "Loss: 4.044169\n",
      "Starting epoch 36\n",
      "Loss: 4.031728\n",
      "Starting epoch 37\n",
      "Loss: 4.020104\n",
      "Starting epoch 38\n",
      "Loss: 4.012279\n",
      "Starting epoch 39\n",
      "Loss: 3.998236\n",
      "Starting epoch 40\n",
      "Loss: 3.988636\n",
      "Starting epoch 41\n",
      "Loss: 3.983064\n",
      "Starting epoch 42\n",
      "Loss: 3.975317\n",
      "Starting epoch 43\n",
      "Loss: 3.958799\n",
      "Starting epoch 44\n",
      "Loss: 3.949830\n",
      "Starting epoch 45\n",
      "Loss: 3.943485\n",
      "Starting epoch 46\n",
      "Loss: 3.932076\n",
      "Starting epoch 47\n",
      "Loss: 3.915120\n",
      "Starting epoch 48\n",
      "Loss: 3.905694\n",
      "Starting epoch 49\n",
      "Loss: 3.910922\n",
      "Starting epoch 50\n",
      "Loss: 3.889190\n",
      "Starting epoch 51\n",
      "Loss: 3.912489\n",
      "Starting epoch 52\n",
      "Loss: 3.955702\n",
      "Starting epoch 53\n",
      "Loss: 3.933849\n",
      "Starting epoch 54\n",
      "Loss: 4.011112\n",
      "Starting epoch 55\n",
      "Loss: 3.939760\n",
      "Starting epoch 56\n",
      "Loss: 3.973940\n",
      "Starting epoch 57\n",
      "Loss: 3.932909\n",
      "Starting epoch 58\n",
      "Loss: 3.948866\n",
      "Starting epoch 59\n",
      "Loss: 3.911660\n",
      "Starting epoch 60\n",
      "Loss: 3.921868\n",
      "Starting epoch 61\n",
      "Loss: 3.916135\n",
      "Starting epoch 62\n",
      "Loss: 3.895700\n",
      "Starting epoch 63\n",
      "Loss: 3.905352\n",
      "Starting epoch 64\n",
      "Loss: 3.873143\n",
      "Starting epoch 65\n",
      "Loss: 3.858460\n",
      "Starting epoch 66\n",
      "Loss: 3.810421\n",
      "Starting epoch 67\n",
      "Loss: 3.981654\n",
      "Starting epoch 68\n",
      "Loss: 3.919423\n",
      "Starting epoch 69\n",
      "Loss: 4.007947\n",
      "Starting epoch 70\n",
      "Loss: 4.022665\n",
      "Starting epoch 71\n",
      "Loss: 4.002283\n",
      "Starting epoch 72\n",
      "Loss: 3.925539\n",
      "Starting epoch 73\n",
      "Loss: 3.887705\n",
      "Starting epoch 74\n",
      "Loss: 3.951772\n",
      "Starting epoch 75\n",
      "Loss: 3.874851\n",
      "Starting epoch 76\n",
      "Loss: 3.918368\n",
      "Starting epoch 77\n",
      "Loss: 3.922451\n",
      "Starting epoch 78\n",
      "Loss: 3.876385\n",
      "Starting epoch 79\n",
      "Loss: 3.853463\n",
      "Starting epoch 80\n",
      "Loss: 3.916604\n",
      "Starting epoch 81\n",
      "Loss: 3.850993\n",
      "Starting epoch 82\n",
      "Loss: 3.861316\n",
      "Starting epoch 83\n",
      "Loss: 3.873849\n",
      "Starting epoch 84\n",
      "Loss: 3.863252\n",
      "Starting epoch 85\n",
      "Loss: 3.845294\n",
      "Starting epoch 86\n",
      "Loss: 3.840006\n",
      "Starting epoch 87\n",
      "Loss: 3.853203\n",
      "Starting epoch 88\n",
      "Loss: 3.830091\n",
      "Starting epoch 89\n",
      "Loss: 3.831454\n",
      "Starting epoch 90\n",
      "Loss: 3.835929\n",
      "Starting epoch 91\n",
      "Loss: 3.830140\n",
      "Starting epoch 92\n",
      "Loss: 3.815060\n",
      "Starting epoch 93\n",
      "Loss: 3.817273\n",
      "Starting epoch 94\n",
      "Loss: 3.815895\n",
      "Starting epoch 95\n",
      "Loss: 3.804659\n",
      "Starting epoch 96\n",
      "Loss: 3.809889\n",
      "Starting epoch 97\n",
      "Loss: 3.804523\n",
      "Starting epoch 98\n",
      "Loss: 3.794703\n",
      "Starting epoch 99\n",
      "Loss: 3.800989\n",
      "Starting epoch 100\n",
      "Loss: 3.792006\n",
      "Starting epoch 101\n",
      "Loss: 3.788166\n",
      "Starting epoch 102\n",
      "Loss: 3.787950\n",
      "Starting epoch 103\n",
      "Loss: 3.782658\n",
      "Starting epoch 104\n",
      "Loss: 3.780759\n",
      "Starting epoch 105\n",
      "Loss: 3.774373\n",
      "Starting epoch 106\n",
      "Loss: 3.773571\n",
      "Starting epoch 107\n",
      "Loss: 3.771809\n",
      "Starting epoch 108\n",
      "Loss: 3.765415\n",
      "Starting epoch 109\n",
      "Loss: 3.764965\n",
      "Starting epoch 110\n",
      "Loss: 3.760423\n",
      "Starting epoch 111\n",
      "Loss: 3.759315\n",
      "Starting epoch 112\n",
      "Loss: 3.754898\n",
      "Starting epoch 113\n",
      "Loss: 3.752000\n",
      "Starting epoch 114\n",
      "Loss: 3.749308\n",
      "Starting epoch 115\n",
      "Loss: 3.746907\n",
      "Starting epoch 116\n",
      "Loss: 3.744519\n",
      "Starting epoch 117\n",
      "Loss: 3.741408\n",
      "Starting epoch 118\n",
      "Loss: 3.738993\n",
      "Starting epoch 119\n",
      "Loss: 3.736331\n",
      "Starting epoch 120\n",
      "Loss: 3.733858\n",
      "Starting epoch 121\n",
      "Loss: 3.731965\n",
      "Starting epoch 122\n",
      "Loss: 3.730160\n",
      "Starting epoch 123\n",
      "Loss: 3.730693\n",
      "Starting epoch 124\n",
      "Loss: 3.732091\n",
      "Starting epoch 125\n",
      "Loss: 3.736177\n",
      "Starting epoch 126\n",
      "Loss: 3.734909\n",
      "Starting epoch 127\n",
      "Loss: 3.726591\n",
      "Starting epoch 128\n",
      "Loss: 3.715908\n",
      "Starting epoch 129\n",
      "Loss: 3.711213\n",
      "Starting epoch 130\n",
      "Loss: 3.714566\n",
      "Starting epoch 131\n",
      "Loss: 3.716478\n",
      "Starting epoch 132\n",
      "Loss: 3.713566\n",
      "Starting epoch 133\n",
      "Loss: 3.706205\n",
      "Starting epoch 134\n",
      "Loss: 3.700751\n",
      "Starting epoch 135\n",
      "Loss: 3.701129\n",
      "Starting epoch 136\n",
      "Loss: 3.702776\n",
      "Starting epoch 137\n",
      "Loss: 3.702595\n",
      "Starting epoch 138\n",
      "Loss: 3.698600\n",
      "Starting epoch 139\n",
      "Loss: 3.692818\n",
      "Starting epoch 140\n",
      "Loss: 3.689690\n",
      "Starting epoch 141\n",
      "Loss: 3.688878\n",
      "Starting epoch 142\n",
      "Loss: 3.689503\n",
      "Starting epoch 143\n",
      "Loss: 3.690030\n",
      "Starting epoch 144\n",
      "Loss: 3.688196\n",
      "Starting epoch 145\n",
      "Loss: 3.685188\n",
      "Starting epoch 146\n",
      "Loss: 3.681246\n",
      "Starting epoch 147\n",
      "Loss: 3.677832\n",
      "Starting epoch 148\n",
      "Loss: 3.675897\n",
      "Starting epoch 149\n",
      "Loss: 3.674760\n",
      "Starting epoch 150\n",
      "Loss: 3.674417\n",
      "Starting epoch 151\n",
      "Loss: 3.674661\n",
      "Starting epoch 152\n",
      "Loss: 3.675090\n",
      "Starting epoch 153\n",
      "Loss: 3.676061\n",
      "Starting epoch 154\n",
      "Loss: 3.677091\n",
      "Starting epoch 155\n",
      "Loss: 3.677054\n",
      "Starting epoch 156\n",
      "Loss: 3.675023\n",
      "Starting epoch 157\n",
      "Loss: 3.670387\n",
      "Starting epoch 158\n",
      "Loss: 3.664685\n",
      "Starting epoch 159\n",
      "Loss: 3.660161\n",
      "Starting epoch 160\n",
      "Loss: 3.658083\n",
      "Starting epoch 161\n",
      "Loss: 3.658202\n",
      "Starting epoch 162\n",
      "Loss: 3.659478\n",
      "Starting epoch 163\n",
      "Loss: 3.660647\n",
      "Starting epoch 164\n",
      "Loss: 3.660758\n",
      "Starting epoch 165\n",
      "Loss: 3.659462\n",
      "Starting epoch 166\n",
      "Loss: 3.656337\n",
      "Starting epoch 167\n",
      "Loss: 3.652560\n",
      "Starting epoch 168\n",
      "Loss: 3.648999\n",
      "Starting epoch 169\n",
      "Loss: 3.646444\n",
      "Starting epoch 170\n",
      "Loss: 3.645112\n",
      "Starting epoch 171\n",
      "Loss: 3.644729\n",
      "Starting epoch 172\n",
      "Loss: 3.644922\n",
      "Starting epoch 173\n",
      "Loss: 3.645520\n",
      "Starting epoch 174\n",
      "Loss: 3.646631\n",
      "Starting epoch 175\n",
      "Loss: 3.647884\n",
      "Starting epoch 176\n",
      "Loss: 3.649615\n",
      "Starting epoch 177\n",
      "Loss: 3.650482\n",
      "Starting epoch 178\n",
      "Loss: 3.650036\n",
      "Starting epoch 179\n",
      "Loss: 3.646182\n",
      "Starting epoch 180\n",
      "Loss: 3.640315\n",
      "Starting epoch 181\n",
      "Loss: 3.634297\n",
      "Starting epoch 182\n",
      "Loss: 3.631200\n",
      "Starting epoch 183\n",
      "Loss: 3.631497\n",
      "Starting epoch 184\n",
      "Loss: 3.633435\n",
      "Starting epoch 185\n",
      "Loss: 3.634917\n",
      "Starting epoch 186\n",
      "Loss: 3.634179\n",
      "Starting epoch 187\n",
      "Loss: 3.631584\n",
      "Starting epoch 188\n",
      "Loss: 3.627774\n",
      "Starting epoch 189\n",
      "Loss: 3.624576\n",
      "Starting epoch 190\n",
      "Loss: 3.622935\n",
      "Starting epoch 191\n",
      "Loss: 3.622797\n",
      "Starting epoch 192\n",
      "Loss: 3.623401\n",
      "Starting epoch 193\n",
      "Loss: 3.623884\n",
      "Starting epoch 194\n",
      "Loss: 3.623927\n",
      "Starting epoch 195\n",
      "Loss: 3.623062\n",
      "Starting epoch 196\n",
      "Loss: 3.621637\n",
      "Starting epoch 197\n",
      "Loss: 3.619566\n",
      "Starting epoch 198\n",
      "Loss: 3.617431\n",
      "Starting epoch 199\n",
      "Loss: 3.615386\n",
      "Starting epoch 200\n",
      "Loss: 3.613711\n",
      "Starting epoch 201\n",
      "Loss: 3.612442\n",
      "Starting epoch 202\n",
      "Loss: 3.611510\n",
      "Starting epoch 203\n",
      "Loss: 3.610847\n",
      "Starting epoch 204\n",
      "Loss: 3.610404\n",
      "Starting epoch 205\n",
      "Loss: 3.610241\n",
      "Starting epoch 206\n",
      "Loss: 3.610499\n",
      "Starting epoch 207\n",
      "Loss: 3.611691\n",
      "Starting epoch 208\n",
      "Loss: 3.614427\n",
      "Starting epoch 209\n",
      "Loss: 3.620747\n",
      "Starting epoch 210\n",
      "Loss: 3.632116\n",
      "Starting epoch 211\n",
      "Loss: 3.652689\n",
      "Starting epoch 212\n",
      "Loss: 3.673335\n",
      "Starting epoch 213\n",
      "Loss: 3.672722\n",
      "Starting epoch 214\n",
      "Loss: 3.627922\n",
      "Starting epoch 215\n",
      "Loss: 3.602351\n",
      "Starting epoch 216\n",
      "Loss: 3.628258\n",
      "Starting epoch 217\n",
      "Loss: 3.627705\n",
      "Starting epoch 218\n",
      "Loss: 3.601129\n",
      "Starting epoch 219\n",
      "Loss: 3.610293\n",
      "Starting epoch 220\n",
      "Loss: 3.618316\n",
      "Starting epoch 221\n",
      "Loss: 3.599863\n",
      "Starting epoch 222\n",
      "Loss: 3.603072\n",
      "Starting epoch 223\n",
      "Loss: 3.609837\n",
      "Starting epoch 224\n",
      "Loss: 3.596976\n",
      "Starting epoch 225\n",
      "Loss: 3.599027\n",
      "Starting epoch 226\n",
      "Loss: 3.603261\n",
      "Starting epoch 227\n",
      "Loss: 3.594098\n",
      "Starting epoch 228\n",
      "Loss: 3.596150\n",
      "Starting epoch 229\n",
      "Loss: 3.597982\n",
      "Starting epoch 230\n",
      "Loss: 3.591504\n",
      "Starting epoch 231\n",
      "Loss: 3.593241\n",
      "Starting epoch 232\n",
      "Loss: 3.593751\n",
      "Starting epoch 233\n",
      "Loss: 3.589406\n",
      "Starting epoch 234\n",
      "Loss: 3.590639\n",
      "Starting epoch 235\n",
      "Loss: 3.590265\n",
      "Starting epoch 236\n",
      "Loss: 3.587387\n",
      "Starting epoch 237\n",
      "Loss: 3.588305\n",
      "Starting epoch 238\n",
      "Loss: 3.587316\n",
      "Starting epoch 239\n",
      "Loss: 3.585208\n",
      "Starting epoch 240\n",
      "Loss: 3.586011\n",
      "Starting epoch 241\n",
      "Loss: 3.584792\n",
      "Starting epoch 242\n",
      "Loss: 3.582927\n",
      "Starting epoch 243\n",
      "Loss: 3.583514\n",
      "Starting epoch 244\n",
      "Loss: 3.582555\n",
      "Starting epoch 245\n",
      "Loss: 3.580775\n",
      "Starting epoch 246\n",
      "Loss: 3.580932\n",
      "Starting epoch 247\n",
      "Loss: 3.580327\n",
      "Starting epoch 248\n",
      "Loss: 3.578769\n",
      "Starting epoch 249\n",
      "Loss: 3.578522\n",
      "Starting epoch 250\n",
      "Loss: 3.578153\n",
      "Starting epoch 251\n",
      "Loss: 3.576905\n",
      "Starting epoch 252\n",
      "Loss: 3.576361\n",
      "Starting epoch 253\n",
      "Loss: 3.576028\n",
      "Starting epoch 254\n",
      "Loss: 3.575084\n",
      "Starting epoch 255\n",
      "Loss: 3.574409\n",
      "Starting epoch 256\n",
      "Loss: 3.574005\n",
      "Starting epoch 257\n",
      "Loss: 3.573271\n",
      "Starting epoch 258\n",
      "Loss: 3.572591\n",
      "Starting epoch 259\n",
      "Loss: 3.572106\n",
      "Starting epoch 260\n",
      "Loss: 3.571450\n",
      "Starting epoch 261\n",
      "Loss: 3.570834\n",
      "Starting epoch 262\n",
      "Loss: 3.570322\n",
      "Starting epoch 263\n",
      "Loss: 3.569662\n",
      "Starting epoch 264\n",
      "Loss: 3.569087\n",
      "Starting epoch 265\n",
      "Loss: 3.568615\n",
      "Starting epoch 266\n",
      "Loss: 3.567953\n",
      "Starting epoch 267\n",
      "Loss: 3.567354\n",
      "Starting epoch 268\n",
      "Loss: 3.566922\n",
      "Starting epoch 269\n",
      "Loss: 3.566319\n",
      "Starting epoch 270\n",
      "Loss: 3.565695\n",
      "Starting epoch 271\n",
      "Loss: 3.565227\n",
      "Starting epoch 272\n",
      "Loss: 3.564699\n",
      "Starting epoch 273\n",
      "Loss: 3.564106\n",
      "Starting epoch 274\n",
      "Loss: 3.563600\n",
      "Starting epoch 275\n",
      "Loss: 3.563075\n",
      "Starting epoch 276\n",
      "Loss: 3.562535\n",
      "Starting epoch 277\n",
      "Loss: 3.562037\n",
      "Starting epoch 278\n",
      "Loss: 3.561507\n",
      "Starting epoch 279\n",
      "Loss: 3.560964\n",
      "Starting epoch 280\n",
      "Loss: 3.560483\n",
      "Starting epoch 281\n",
      "Loss: 3.559983\n",
      "Starting epoch 282\n",
      "Loss: 3.559452\n",
      "Starting epoch 283\n",
      "Loss: 3.558955\n",
      "Starting epoch 284\n",
      "Loss: 3.558462\n",
      "Starting epoch 285\n",
      "Loss: 3.557956\n",
      "Starting epoch 286\n",
      "Loss: 3.557464\n",
      "Starting epoch 287\n",
      "Loss: 3.556970\n",
      "Starting epoch 288\n",
      "Loss: 3.556459\n",
      "Starting epoch 289\n",
      "Loss: 3.555969\n",
      "Starting epoch 290\n",
      "Loss: 3.555481\n",
      "Starting epoch 291\n",
      "Loss: 3.554971\n",
      "Starting epoch 292\n",
      "Loss: 3.554465\n",
      "Starting epoch 293\n",
      "Loss: 3.553952\n",
      "Starting epoch 294\n",
      "Loss: 3.553422\n",
      "Starting epoch 295\n",
      "Loss: 3.552895\n",
      "Starting epoch 296\n",
      "Loss: 3.552374\n",
      "Starting epoch 297\n",
      "Loss: 3.551842\n",
      "Starting epoch 298\n",
      "Loss: 3.551318\n",
      "Starting epoch 299\n",
      "Loss: 3.550787\n",
      "Starting epoch 300\n",
      "Loss: 3.550248\n",
      "Starting epoch 301\n",
      "Loss: 3.549719\n",
      "Starting epoch 302\n",
      "Loss: 3.549199\n",
      "Starting epoch 303\n",
      "Loss: 3.548705\n",
      "Starting epoch 304\n",
      "Loss: 3.548245\n",
      "Starting epoch 305\n",
      "Loss: 3.547832\n",
      "Starting epoch 306\n",
      "Loss: 3.547475\n",
      "Starting epoch 307\n",
      "Loss: 3.547211\n",
      "Starting epoch 308\n",
      "Loss: 3.547126\n",
      "Starting epoch 309\n",
      "Loss: 3.547355\n",
      "Starting epoch 310\n",
      "Loss: 3.548406\n",
      "Starting epoch 311\n",
      "Loss: 3.551736\n",
      "Starting epoch 312\n",
      "Loss: 3.566837\n",
      "Starting epoch 313\n",
      "Loss: 3.637102\n",
      "Starting epoch 314\n",
      "Loss: 3.618409\n",
      "Starting epoch 315\n",
      "Loss: 3.569804\n",
      "Starting epoch 316\n",
      "Loss: 3.567122\n",
      "Starting epoch 317\n",
      "Loss: 3.570631\n",
      "Starting epoch 318\n",
      "Loss: 3.560238\n",
      "Starting epoch 319\n",
      "Loss: 3.575670\n",
      "Starting epoch 320\n",
      "Loss: 3.612742\n",
      "Starting epoch 321\n",
      "Loss: 3.628713\n",
      "Starting epoch 322\n",
      "Loss: 3.592626\n",
      "Starting epoch 323\n",
      "Loss: 3.733497\n",
      "Starting epoch 324\n",
      "Loss: 3.640812\n",
      "Starting epoch 325\n",
      "Loss: 3.729455\n",
      "Starting epoch 326\n",
      "Loss: 3.739149\n",
      "Starting epoch 327\n",
      "Loss: 3.602584\n",
      "Starting epoch 328\n",
      "Loss: 3.708958\n",
      "Starting epoch 329\n",
      "Loss: 3.638761\n",
      "Starting epoch 330\n",
      "Loss: 3.662737\n",
      "Starting epoch 331\n",
      "Loss: 3.663867\n",
      "Starting epoch 332\n",
      "Loss: 3.633608\n",
      "Starting epoch 333\n",
      "Loss: 3.606439\n",
      "Starting epoch 334\n",
      "Loss: 3.659746\n",
      "Starting epoch 335\n",
      "Loss: 3.632677\n",
      "Starting epoch 336\n",
      "Loss: 3.620045\n",
      "Starting epoch 337\n",
      "Loss: 3.636766\n",
      "Starting epoch 338\n",
      "Loss: 3.648729\n",
      "Starting epoch 339\n",
      "Loss: 3.596158\n",
      "Starting epoch 340\n",
      "Loss: 3.592067\n",
      "Starting epoch 341\n",
      "Loss: 3.604444\n",
      "Starting epoch 342\n",
      "Loss: 3.599647\n",
      "Starting epoch 343\n",
      "Loss: 3.574002\n",
      "Starting epoch 344\n",
      "Loss: 3.582099\n",
      "Starting epoch 345\n",
      "Loss: 3.605422\n",
      "Starting epoch 346\n",
      "Loss: 3.573955\n",
      "Starting epoch 347\n",
      "Loss: 3.568501\n",
      "Starting epoch 348\n",
      "Loss: 3.579986\n",
      "Starting epoch 349\n",
      "Loss: 3.571318\n",
      "Starting epoch 350\n",
      "Loss: 3.568336\n",
      "Starting epoch 351\n",
      "Loss: 3.574494\n",
      "Starting epoch 352\n",
      "Loss: 3.568332\n",
      "Starting epoch 353\n",
      "Loss: 3.561875\n",
      "Starting epoch 354\n",
      "Loss: 3.571229\n",
      "Starting epoch 355\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "python_error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-627364ba3c6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \"\"\"\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    121\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    122\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: python_error"
     ]
    }
   ],
   "source": [
    "recording = np.load('train_unified/recording0.npy', allow_pickle=True)\n",
    "instruments_np = np.load('train_unified/instruments0.npy', allow_pickle=True)\n",
    "\n",
    "nsamples = 500\n",
    "\n",
    "history = torch.tensor(recording[:nsamples], dtype=torch.long).view(-1, 1, 2)\n",
    "mask = torch.zeros((history.shape[0], history.shape[1]), dtype=torch.bool)\n",
    "instruments = torch.tensor([instrument_numbers.index(i) for i in instruments_np], dtype=torch.long).view(-1, 1)\n",
    "inst_mask = torch.zeros(instruments.shape, dtype=torch.bool)\n",
    "\n",
    "batch_size = 1\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "message_loss = torch.nn.CrossEntropyLoss()\n",
    "channel_loss = torch.nn.NLLLoss(ignore_index=-1)\n",
    "epochs = 500\n",
    "train_losses = np.zeros(epochs)\n",
    "\n",
    "target_messages = history[1:, :, 0].flatten()\n",
    "target_channels = history[1:, :, 1].flatten()\n",
    "\n",
    "num_channels = instruments_np.shape[0]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('Starting epoch %d' %(epoch))\n",
    "    \n",
    "    message_logits, channel_dist = model(history[:-1], mask[:-1], instruments, inst_mask)\n",
    "    channel_log_dist = torch.log(channel_dist + 1e-8)\n",
    "    \n",
    "    loss = message_loss(message_logits.view(-1, message_dim), target_messages) + \\\n",
    "           channel_loss(channel_log_dist.view(-1, num_channels), target_channels)\n",
    "                \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_losses[epoch] = loss.data\n",
    "    print('Loss: %f' %(loss.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'unified_transformer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbae2cab190>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sample from model\n",
    "gen_history = history[0].unsqueeze(0)\n",
    "gen_mask = torch.zeros((1, 1), dtype=torch.bool)\n",
    "model.eval() # Turns off the dropout for evaluation. Need to do this to get repeatable evaluation outputs\n",
    "\n",
    "# Move forward in time\n",
    "wrong_cnt = 0\n",
    "for t in range(0, history.shape[0] - 1):\n",
    "    message_logits, channel_dist = model(gen_history, gen_mask, instruments, inst_mask)\n",
    "    print(channel_dist[-1])\n",
    "    \n",
    "    #message = torch.multinomial(torch.softmax(message_logits[-1].flatten(), dim=0), 1)\n",
    "    #channel = torch.multinomial(channel_dist[-1].flatten(), 1)\n",
    "    \n",
    "    message = torch.argmax(message_logits[-1].flatten())\n",
    "    channel = torch.argmax(channel_dist[-1].flatten())\n",
    "    \n",
    "    append = torch.tensor([message, channel]).view(1, 1, 2)\n",
    "    \n",
    "    gen_history = torch.cat((gen_history, append), dim=0)\n",
    "    \n",
    "    if gen_history[-1, 0, 0] != history[t + 1, 0, 0]:\n",
    "        print('Wrong message at time %d!' %(t))\n",
    "        wrong_cnt += 1\n",
    "        \n",
    "    if gen_history[-1, 0, 1] != history[t + 1, 0, 1]:\n",
    "        print('Wrong instrument at time %d!' %(t))\n",
    "        wrong_cnt += 1\n",
    "    \n",
    "    gen_mask = torch.cat((gen_mask, torch.zeros((1, 1), dtype=torch.bool)), dim=0)\n",
    "\n",
    "print(wrong_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('test_history.npy', gen_history.squeeze(1).detach().numpy())\n",
    "np.save('test_instruments.npy', [instrument_numbers[i] for i in instruments[:-1, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class\n",
    "class MIDIDataset(torch.utils.data.Dataset):\n",
    "    # CONSTRUCTOR: creates a list of recording files and a list\n",
    "    # of instrument files in root_dir. Assumes that the directory\n",
    "    # contains recording0.npy to recordingM.npy,\n",
    "    # as well as instruments0.npy to instrumentsM.npy\n",
    "    # ARGUMENTS\n",
    "    # root_dir: the directory to search\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        files = os.listdir(root_dir)\n",
    "        self.recording_files = []\n",
    "        self.instrument_files = []\n",
    "        for file in files:\n",
    "            if 'recording' in file:\n",
    "                self.recording_files.append(os.path.join(root_dir, file))\n",
    "            elif 'instruments' in file:\n",
    "                self.instrument_files.append(os.path.join(root_dir, file))\n",
    "                \n",
    "        assert(len(self.recording_files) == len(self.instrument_files))\n",
    "        self.recording_files.sort()\n",
    "        self.instrument_files.sort()\n",
    "        \n",
    "        self.recordings = []\n",
    "        self.instruments = []\n",
    "        for f in range(len(self.recording_files)):\n",
    "            self.recordings.append(np.load(self.recording_files[f], allow_pickle=True))\n",
    "            self.instruments.append(np.load(self.instrument_files[f], allow_pickle=True))\n",
    "            \n",
    "        self.transform = transform\n",
    "\n",
    "    # __len__\n",
    "    # RETURN: the number of recording files in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.recordings)\n",
    "\n",
    "    # __getitem__\n",
    "    # ARGUMENTS\n",
    "    # idx: indicates which file to get\n",
    "    # RETURN: an instance with keys 'instruments', 'history'\n",
    "    # instance['history'] is an Lx2 numpy array containing messages and associated channels\n",
    "    # instance['instruments'] a numpy array of instrument numbers\n",
    "    def __getitem__(self, idx):\n",
    "        instance = {'history': self.recordings[idx], \\\n",
    "                    'instruments': self.instruments[idx]}\n",
    "        \n",
    "        if self.transform:\n",
    "            instance = self.transform(instance)\n",
    "            \n",
    "        return instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collate_fn: takes a list of samples from the dataset and turns them into a batch.\n",
    "# ARGUMENTS\n",
    "# batch: a list of dictionaries\n",
    "# RETURN: a sample with keys 'history', 'instruments', and 'mask'\n",
    "# sample['history']: an LxBx2 tensor containing messages and their associated channels\n",
    "# sample['instruments']: a CxB tensor containing instrument numbers for each channel\n",
    "# sample['mask']: an LxB tensor containing False where a message is\n",
    "# valid, and True where it isn't (accounts for variable length sequences\n",
    "# and zero padding)\n",
    "# sample['nchan']: a length B tensor containing the number of channels for each batch\n",
    "# element (including the dummy time-shift channel)\n",
    "def collate_fn(batch):\n",
    "    batch_size = len(batch)\n",
    "    \n",
    "    # We size our tensors to accomodate the longest sequence and the largest number of instruments\n",
    "    max_inst = max([instance['instruments'].shape[0] for instance in batch])\n",
    "    longest_len = max([instance['history'].shape[0] for instance in batch])\n",
    "\n",
    "    sample = {'history': torch.zeros((longest_len, batch_size, 2), dtype=torch.long), \\\n",
    "              'instruments': torch.zeros((max_inst, batch_size), dtype=torch.long), \\\n",
    "              'mask': torch.ones((longest_len, batch_size), dtype=torch.bool), \\\n",
    "              'inst_mask': torch.ones((max_inst, batch_size), dtype=torch.bool)}\n",
    "\n",
    "    for b, instance in enumerate(batch):\n",
    "        instrument_idx = [instrument_numbers.index(i) for i in instance['instruments']]\n",
    "        \n",
    "        sample['instruments'][:len(instrument_idx), b] = torch.tensor(instrument_idx, dtype=torch.long)\n",
    "        \n",
    "        sample['inst_mask'][:len(instrument_idx), b] = False\n",
    "        \n",
    "        seq_length = instance['history'].shape[0]\n",
    "        sample['history'][:seq_length, b] = torch.tensor(instance['history'], dtype=torch.long)\n",
    "        sample['mask'][:seq_length, b] = False\n",
    "            \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_loss: computes the loss for the model over the batch\n",
    "# ARGUMENTS\n",
    "# model: EnsembleTransformer model\n",
    "# loss_fn: torch.nn.CrossEntropyLoss object\n",
    "# batch: see collate_fn definition\n",
    "# RETURN: a scalar loss tensor\n",
    "def compute_loss(model, loss_fn, batch):\n",
    "    batch_size = batch['history'].shape[1]\n",
    "    \n",
    "    max_seq_length = batch['history'].shape[0]\n",
    "        \n",
    "    num_targets = max_seq_length - 1 # Messages start from t = 0, but we start generating at t = 1\n",
    "\n",
    "    message_logits, channel_logits = model(batch['history'][:-1], batch['mask'][:-1], batch['instruments'])\n",
    "\n",
    "    target_mask = torch.logical_not(batch['mask'][1:])\n",
    "\n",
    "    num_valid_targets = target_mask.sum()\n",
    "\n",
    "    target_messages = batch['history'][1:, :, 0][target_mask]\n",
    "\n",
    "    message_loss = loss_fn(message_logits[target_mask], target_messages)/num_valid_targets\n",
    "\n",
    "    channel_losses = torch.zeros(batch_size)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        channel_logits_i = channel_logits[:, i, :batch['nchan'][i]][target_mask[:, i]]\n",
    "        target_channels = batch['history'][1:, i, 1][target_mask[:, i]]\n",
    "        \n",
    "        time_shift_mask = target_channels >= 0\n",
    "        channel_losses[i] = loss_fn(channel_logits_i[time_shift_mask], target_channels[time_shift_mask])/num_valid_targets\n",
    "\n",
    "    return message_loss + channel_losses.sum()\n",
    "\n",
    "# compute_loss: computes the loss for the model over the batch\n",
    "# ARGUMENTS\n",
    "# model: EnsembleTransformer model\n",
    "# message_loss_fn: torch.nn.CrossEntropyLoss object\n",
    "# channel_loss_fn: torch.nn.NLLLoss object\n",
    "# batch: see collate_fn definition\n",
    "# RETURN: a scalar loss tensor\n",
    "def compute_loss(model, message_loss_fn, batch):  \n",
    "    max_seq_length = batch['history'].shape[0]\n",
    "        \n",
    "    num_targets = max_seq_length - 1 # Messages start from t = 0, but we start generating at t = 1\n",
    "\n",
    "    message_logits, channel_dist = model(batch['history'][:-1], batch['mask'][:-1], batch['instruments'], batch['inst_mask'])\n",
    "    log_channel_dist = torch.log(channel_dist + 1e-10)\n",
    "\n",
    "    target_mask = torch.logical_not(batch['mask'][1:])\n",
    "\n",
    "    message_loss = message_loss_fn(message_logits[target_mask], batch['history'][1:, :, 0][target_mask])\n",
    "    channel_loss = loss_fn(log_channel_dist[target_mask], batch['history'][1:, :, 1][target_mask])\n",
    "\n",
    "    return message_loss + channel_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 512\n",
    "heads = 4\n",
    "attention_layers = 6\n",
    "ff_size = 512\n",
    "\n",
    "grad_clip = 10\n",
    "\n",
    "model = EnsembleTransformer(message_dim, embed_dim, num_instruments, heads, attention_layers, ff_size)\n",
    "for p in model.parameters():\n",
    "    p.register_hook(lambda grad: torch.clamp(grad, -grad_clip, grad_clip))\n",
    "    \n",
    "model.eval() # Training with eval just to see if we can overfit without dropout\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "learning_rate = 0.001\n",
    "chunk_size = 500\n",
    "\n",
    "train_dataset = MIDIDataset('train_unified')\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "test_dataset = MIDIDataset('test_unified')\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "epochs = 20\n",
    "train_losses = np.zeros(epochs)\n",
    "test_losses = np.zeros(epochs)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('Starting epoch %d' %(epoch))\n",
    "    model.train()\n",
    "    for b, batch in enumerate(train_dataloader):\n",
    "        print('Starting iteration %d' %(b))\n",
    "        for chunk_start in range(0, batch['history'].shape[0] - 1, chunk_size):\n",
    "            chunk_end = min(batch['history'].shape[0], chunk_start + chunk_size)\n",
    "            \n",
    "            chunk = {'history': batch['history'][chunk_start:chunk_end],\n",
    "                     'instruments': batch['instruments'],\n",
    "                     'mask': batch['mask'][chunk_start:chunk_end],\n",
    "                     'inst_mask': batch['inst_mask']}\n",
    "\n",
    "            loss = compute_loss(model, loss_fn, chunk)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "    torch.save(model.state_dict(), 'unified_transformer_models/epoch' + str(epoch) + '.pth')\n",
    "\n",
    "    print('Computing test loss')\n",
    "    model.eval()\n",
    "    for batch in test_dataloader:\n",
    "        for chunk_start in range(0, batch['history'].shape[0] - 1, chunk_size):\n",
    "            chunk_end = min(batch['history'].shape[0], chunk_start + chunk_size)\n",
    "            \n",
    "            chunk = {'history': batch['history'][chunk_start:chunk_end],\n",
    "                     'instruments': batch['instruments'],\n",
    "                     'mask': batch['mask'][chunk_start:chunk_end],\n",
    "                     'inst_mask': batch['inst_mask']}\n",
    "\n",
    "            loss = compute_loss(model, loss_fn, chunk)\n",
    "            test_losses[epoch] += loss.data\n",
    "        \n",
    "    print('Computing train loss')\n",
    "    for batch in train_dataloader:\n",
    "        for chunk_start in range(0, batch['history'].shape[0] - 1, chunk_size):\n",
    "            chunk_end = min(batch['history'].shape[0], chunk_start + chunk_size)\n",
    "            \n",
    "            chunk = {'history': batch['history'][chunk_start:chunk_end],\n",
    "                     'instruments': batch['instruments'],\n",
    "                     'mask': batch['mask'][chunk_start:chunk_end],\n",
    "                     'inst_mask': batch['inst_mask']}\n",
    "\n",
    "            loss = compute_loss(model, loss_fn, chunk)\n",
    "            train_losses[epoch] += loss.data\n",
    "    \n",
    "    train_losses[epoch] /= len(train_dataloader)\n",
    "    test_losses[epoch] /= len(test_dataloader)\n",
    "    print('Train Loss: %f, Test Loss: %f' %(train_losses[epoch], test_losses[epoch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() # Disable dropout to make results repeatable\n",
    "\n",
    "time_steps = 500 # How many time steps do we sample?\n",
    "\n",
    "# Start with a time shift\n",
    "gen_history = torch.zeros((1, 1, 2), dtype=torch.long)\n",
    "gen_history[0, 0, 0] = 387\n",
    "gen_history[0, 0, 1] = -1\n",
    "\n",
    "# Violin\n",
    "instruments = torch.zeros((1, 1), dtype=torch.long)\n",
    "instruments[0, 0] = 0\n",
    "inst_mask = torch.zeros((1, 1), dtype=torch.bool)\n",
    "\n",
    "gen_mask = torch.zeros((1, 1), dtype=torch.bool)\n",
    "\n",
    "# Move forward in time\n",
    "for t in range(0, time_steps):\n",
    "    message_logits, channel_logits = model(gen_history, gen_mask, instruments)\n",
    "    \n",
    "    message = torch.multinomial(torch.softmax(message_logits[-1].flatten(), dim=0), 1)\n",
    "    channel = torch.multinomial(channel_logits[-1].flatten(), 1)\n",
    "    \n",
    "    append = torch.tensor([message, channel]).view(1, 1, 2)\n",
    "    \n",
    "    gen_history = torch.cat((gen_history, append), dim=0)\n",
    "    \n",
    "    gen_mask = torch.cat((gen_mask, torch.zeros((1, 1), dtype=torch.bool)), dim=0)\n",
    "\n",
    "print(wrong_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('gen_history.npy', gen_history.squeeze(1).detach().numpy())\n",
    "np.save('gen_instruments.npy', [instrument_numbers[i] for i in instruments[:, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-6.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-6:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
