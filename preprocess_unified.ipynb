{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Faure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pretty_midi/pretty_midi.py:101: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Schubert\n",
      "Starting Cambini\n",
      "Starting Ravel\n",
      "Starting Bach\n",
      "Starting Dvorak\n",
      "Starting Brahms\n",
      "Starting Mozart\n",
      "Starting Beethoven\n",
      "Starting Haydn\n"
     ]
    }
   ],
   "source": [
    "import pretty_midi\n",
    "import os\n",
    "import numpy as np\n",
    "import heapq\n",
    "import pickle\n",
    "\n",
    "# See https://jazz-soft.net/demo/GeneralMidi.html for which instrument each number represents\n",
    "instrument_numbers = [0, 6, 40, 41, 42, 43, 45, 60, 68, 70, 71, 73]\n",
    "num_instruments = len(instrument_numbers)\n",
    "\n",
    "num_notes = 128 # Number of pitches in MIDI\n",
    "\n",
    "# We allow the network to step itself forward in time in increments of 10 ms.\n",
    "# Thus the network can shift between 10 ms and 1 s, inclusive\n",
    "num_time_shifts = 100 \n",
    "min_time_shift = 0.01\n",
    "\n",
    "# A message can be NOTE_ON, NOTE_OFF, TIME_SHIFT\n",
    "message_dim = 2*num_notes + num_time_shifts\n",
    "\n",
    "# quantize_time_shift: takes a time shift and puts it into the correct bin\n",
    "# in our reduced representation\n",
    "# ARGUMENTS\n",
    "# time_shift: the number of seconds to shift\n",
    "# RETURN: the quantized time shift\n",
    "def quantize_time_shift(time_shift):\n",
    "    return int(np.round(time_shift/min_time_shift)) - 1\n",
    "\n",
    "# note_on_event: generates the index for a NOTE_ON event\n",
    "# ARGUMENTS\n",
    "# note: the MIDI number for the note to be played\n",
    "# RETURN: the index for a NOTE_ON message\n",
    "def note_on_event(note):\n",
    "    return note\n",
    "\n",
    "# note_off_event: generates the index for a NOTE_OFF event\n",
    "# ARGUMENTS\n",
    "# note: the MIDI number for the note to be turned off\n",
    "# RETURN: the index for the NOTE_OFF message\n",
    "def note_off_event(note):\n",
    "    return num_notes + note\n",
    "\n",
    "# time_shift_event: generates the index for a TIME_SHIFT event\n",
    "# ARGUMENTS\n",
    "# time_shift: the quantized time shift\n",
    "# RETURN: the index of the TIME_SHIFT message\n",
    "def time_shift_event(time_shift):\n",
    "    assert(0 <= time_shift and time_shift < num_time_shifts)\n",
    "    return 2*num_notes + time_shift\n",
    "\n",
    "# append_time_shift: appends a time shift event to the data array. If the time\n",
    "# shift is too large, split it into multiple small time shifts\n",
    "# ARGUMENTS\n",
    "# data: time shift events will be appended to this list\n",
    "# time_shift: amount of time to shift\n",
    "def append_time_shift(data, time_shift):\n",
    "    time_shift = quantize_time_shift(time_shift)\n",
    "    \n",
    "    # Split large time shifts into multiple small time shifts\n",
    "    while (time_shift >= num_time_shifts):\n",
    "        data.append(time_shift_event(num_time_shifts - 1))\n",
    "        time_shift -= (num_time_shifts - 1)\n",
    "\n",
    "    if (time_shift >= 0):\n",
    "        data.append(time_shift_event(time_shift))\n",
    "    \n",
    "base_path = 'musicnet_midis/'\n",
    "\n",
    "fnum = 0 # Which file are we writing currently?\n",
    "\n",
    "data_fnames = [] # Save file name corresponding to each numpy array\n",
    "\n",
    "train = 0\n",
    "\n",
    "for composer in os.listdir(base_path):\n",
    "    print('Starting ' + composer)\n",
    "    for fname in os.listdir(base_path + composer):\n",
    "        try:\n",
    "            mid = pretty_midi.PrettyMIDI(base_path + composer + '/' + fname)\n",
    "        except:\n",
    "            # There are 7 files that cause an IO error, both with mido and pretty_midi. Haven't looked into why\n",
    "            continue\n",
    "        \n",
    "        # We'll save the final data in an Lx2 numpy array, where L is the total number of messages. Along the second dimension,\n",
    "        # the first element is the message number, and the second element is the channel number\n",
    "        \n",
    "        # We also save an instruments array where element i contains the instrument program number associated with channel i\n",
    "        instruments = []\n",
    "        \n",
    "        # First we store lists and convert to numpy arrays later\n",
    "        data = []\n",
    "        channels = []\n",
    "        \n",
    "        # Store the time of each message. These won't appear in the final data array\n",
    "        times = []\n",
    "        \n",
    "        for i, instrument in enumerate(mid.instruments):          \n",
    "            # Priority queue of notes to turn off and the times to turn them off.\n",
    "            # Specifically, this is a list of tuples of the form (off_time, pitch),\n",
    "            # where the first element of the list is always the next note to turn off\n",
    "            off_queue = []\n",
    "            \n",
    "            time = 0\n",
    "                        \n",
    "            for n, note in enumerate(instrument.notes):\n",
    "                # Fixes bug in 'Haydn/2104_op64n5_1.mid' where notes 674 and 675 are the same note\n",
    "                if n > 0 and note.pitch == instrument.notes[n - 1].pitch and note.start == instrument.notes[n - 1].start:\n",
    "                    continue\n",
    "            \n",
    "                # We need to turn off a note\n",
    "                while off_queue and note.start > off_queue[0][0]:\n",
    "                    data.append(note_off_event(off_queue[0][1]))\n",
    "                    time = off_queue[0][0]\n",
    "                    times.append(time)\n",
    "                    heapq.heappop(off_queue)\n",
    "                    \n",
    "                time = note.start\n",
    "                \n",
    "                data.append(note_on_event(note.pitch))\n",
    "                times.append(time)\n",
    "                \n",
    "                # Add this note to the queue of notes needing to be turned off\n",
    "                heapq.heappush(off_queue, (note.end, note.pitch))\n",
    "                \n",
    "                if n == len(instrument.notes) - 1:\n",
    "                    # No more notes left. Flush the off queue\n",
    "                    while off_queue:\n",
    "                        data.append(note_off_event(off_queue[0][1]))\n",
    "                        time = off_queue[0][0]\n",
    "                        times.append(time)\n",
    "                        heapq.heappop(off_queue)\n",
    "                        \n",
    "            new_messages = len(data) - len(channels)\n",
    "            channels = channels + [i for n in range(new_messages)]\n",
    "            instruments.append(instrument.program)\n",
    "            \n",
    "            assert(len(times) == len(data))\n",
    "        \n",
    "        data = np.array(data, dtype=np.long)\n",
    "        channels = np.array(channels, dtype=np.long)\n",
    "        times = np.array(times, dtype=np.float)\n",
    "        \n",
    "        instruments = np.array(instruments, dtype=np.long)\n",
    "        \n",
    "        sort_idx = np.argsort(times, kind='mergesort')\n",
    "        \n",
    "        data = data[sort_idx]\n",
    "        channels = channels[sort_idx]\n",
    "        times = times[sort_idx]\n",
    "        \n",
    "        data_with_tshifts = []\n",
    "        channels_with_tshifts = []\n",
    "        \n",
    "        for m in range(data.shape[0]):\n",
    "            data_with_tshifts.append(data[m])\n",
    "            channels_with_tshifts.append(channels[m])\n",
    "            if m != data.shape[0] - 1 and times[m] != times[m + 1]:\n",
    "                append_time_shift(data_with_tshifts, times[m + 1] - times[m])\n",
    "                num_append = len(data_with_tshifts) - len(channels_with_tshifts)\n",
    "                \n",
    "                # We say that all time shifts occur on channel -1\n",
    "                channels_with_tshifts = channels_with_tshifts + [-1 for i in range(num_append)]\n",
    "\n",
    "        data_with_tshifts = np.expand_dims(np.array(data_with_tshifts), 1)\n",
    "        channels_with_tshifts = np.expand_dims(np.array(channels_with_tshifts), 1)\n",
    "        data = np.concatenate((data_with_tshifts, channels_with_tshifts), axis=1)\n",
    "        \n",
    "        # 80% train, 20% test\n",
    "        if train == 4:\n",
    "            folder = 'test'\n",
    "        else:\n",
    "            folder = 'train'\n",
    "            \n",
    "        np.save(folder + '_unified/recording' + str(fnum) + '.npy', data)\n",
    "        np.save(folder + '_unified/instruments' + str(fnum) + '.npy', instruments)\n",
    "        \n",
    "        train = (train + 1)%5\n",
    "        \n",
    "        data_fnames.append(composer + '/' + fname)\n",
    "        fnum += 1\n",
    "        \n",
    "pickle.dump(data_fnames, open( \"preprocessed_data_unified_fnames.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Instrument(program=40, is_drum=False, name=\"Violin 1\"),\n",
       " Instrument(program=40, is_drum=False, name=\"Violin 2\"),\n",
       " Instrument(program=41, is_drum=False, name=\"Viola\"),\n",
       " Instrument(program=42, is_drum=False, name=\"Violoncello\")]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mid = pretty_midi.PrettyMIDI(base_path + 'Haydn/2104_op64n5_1.mid')\n",
    "mid.instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "674\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note(start=276.217216, end=276.309321, pitch=78, velocity=49)\n"
     ]
    }
   ],
   "source": [
    "print(mid.instruments[0].notes[674]) # 674 and 675 are the same note"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-6.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-6:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
